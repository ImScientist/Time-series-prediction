{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 Workspace initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Datastore\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path='.env', override=True)\n",
    "# %load_ext dotenv\n",
    "# %dotenv .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 0.1 workspace,  experiment and datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "data_dir = os.environ['DATA_DIR']\n",
    "\n",
    "AML_CONTAINER_REGISTRY_SERVER = os.environ['AML_CONTAINER_REGISTRY_SERVER']\n",
    "AML_CONTAINER_REGISTRY_USR = os.environ['AML_CONTAINER_REGISTRY_USR']\n",
    "AML_CONTAINER_REGISTRY_PWD = os.environ['AML_CONTAINER_REGISTRY_PWD']\n",
    "\n",
    "AML_SERVICE_PRINCIPAL_APP_ID = os.environ['AML_SERVICE_PRINCIPAL_APP_ID']\n",
    "AML_SERVICE_PRINCIPAL_DIR_ID = os.environ[\"AML_SERVICE_PRINCIPAL_DIR_ID\"]\n",
    "AML_SERVICE_PRINCIPAL_PWD = os.environ['AML_SERVICE_PRINCIPAL_PWD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc_pr = ServicePrincipalAuthentication(\n",
    "    tenant_id=AML_SERVICE_PRINCIPAL_DIR_ID,\n",
    "    service_principal_id=AML_SERVICE_PRINCIPAL_APP_ID,\n",
    "    service_principal_password=AML_SERVICE_PRINCIPAL_PWD)\n",
    "\n",
    "# get Workspace\n",
    "# ws = Workspace.from_config(path = os.path.join('aml_config.json'))\n",
    "\n",
    "ws = Workspace(\n",
    "    subscription_id=\"96a9ec41-928f-4f69-9cb4-0a6c396f6ab2\",\n",
    "    resource_group=\"azure-ml\",\n",
    "    workspace_name=\"azure-ml\",\n",
    "    auth=svc_pr\n",
    ")\n",
    "\n",
    "exp = Experiment(workspace=ws, name='rossmann')\n",
    "ds = Datastore.get(ws, datastore_name='workspaceblobstore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure-ml\twesteurope\tazure-ml\t96a9ec41-928f-4f69-9cb4-0a6c396f6ab2\n",
      "\n",
      "datastores\n",
      " {'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore object at 0x114af1990>, 'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore object at 0x114b252d0>}\n"
     ]
    }
   ],
   "source": [
    "print(ws.name, ws.location, ws.resource_group, ws.subscription_id, sep='\\t')\n",
    "print('\\ndatastores\\n', ws.datastores)\n",
    "# print('\\nselected datastore\\n', ds.name, ds.datastore_type, ds.account_name, ds.container_name, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 0.2 upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ds = ws.get_default_datastore()\n",
    "ds = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
    "\n",
    "ds.upload(src_dir=data_dir, target_path='rossmann-store-sales/source', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 0.3 look at available cpus and create a compute instance if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.compute_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "supported_vms = AmlCompute.supported_vmsizes(ws)\n",
    "supported_vms = list(filter(lambda x: x['gpus']==0, supported_vms))\n",
    "supported_vms = sorted(supported_vms, key=lambda x: x['vCPUs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Standard_D1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_DS1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 7168},\n",
       " {'name': 'Standard_D1',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_vms[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"mini-cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D1',\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4, \n",
    "                                                           idle_seconds_before_scaledown=240)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Train localy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 1.1 local run; use locally stored data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- the argument `--n_stores` is used only if we want to apply the model to a subset of the data (only for testing purposes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "run_config.environment.python.interpreter_path = os.environ['PYTHON_INTERPRETER_PATH']\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory='./', \n",
    "                                    script='./train/model_01.py',\n",
    "                                    arguments=['--data_dir', data_dir, \n",
    "                                               '--max_pdq', '6', '1', '4',\n",
    "                                               '--n_stores', '4'],\n",
    "                                    run_config=run_config)\n",
    "\n",
    "\n",
    "run = exp.submit(script_run_config)\n",
    "run.log('comment', 'test local run with locally stored data')\n",
    "# run.log('datastore_name', ds.name)\n",
    "# run.log('path_on_datastore',path_on_datastore)\n",
    "# run.wait_for_completion()\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 1.2 local run; remotely stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "data_dir='rossmann-store-sales/source'\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "run_config.environment.python.interpreter_path = os.environ['PYTHON_INTERPRETER_PATH']\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                                path_on_datastore=data_dir, \n",
    "                                mode='download',\n",
    "                                overwrite=True)\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory='./', \n",
    "                                    script='./train/model_01.py',\n",
    "                                    arguments=['--data_dir', str(ds.as_download()), \n",
    "                                               '--max_pdq', '6', '1', '4',\n",
    "                                               '--n_stores', '4'],\n",
    "                                    run_config=run_config)\n",
    "\n",
    "\n",
    "\n",
    "run = exp.submit(script_run_config)\n",
    "run.log('comment', 'test local run with remotely stored data')\n",
    "run.log('datastore_name', ds.name)\n",
    "run.log('path_on_datastore', data_dir)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 1.5 local run; use conda environment (autoprepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration, DataReferenceConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "data_dir='rossmann-store-sales/source'\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "run_config.auto_prepare_environment = True\n",
    "\n",
    "\n",
    "# cd = CondaDependencies.create(python_version='3.7.3',\n",
    "#                               pip_packages=['pandas', 'numpy', 'scikit-learn', 'azureml-sdk'])\n",
    "cd = CondaDependencies(conda_dependencies_file_path='environment.yml')\n",
    "\n",
    "run_config.environment.python.conda_dependencies = cd\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                                path_on_datastore=data_dir, \n",
    "                                mode='download',\n",
    "                                overwrite=True)\n",
    "\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory='./', \n",
    "                                    script='./train/model_01.py',\n",
    "                                    arguments=['--data_dir', str(ds.as_download()), \n",
    "                                               '--max_pdq', '6', '1', '4',\n",
    "                                               '--n_stores', '4'],\n",
    "                                    run_config=run_config)\n",
    "\n",
    "run = exp.submit(script_run_config)\n",
    "run.log('comment', 'test local run with remotely stored data; use conda environment (autoprepare)')\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 1.10 local run; Docker-based execution (image from Azure registry with user defined Conda env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "FROM continuumio/miniconda3:4.7.12\n",
    "\n",
    "# replace dockers shell used by run to bash such that 'source activate' works\n",
    "RUN ln -fs /bin/bash /bin/sh\n",
    "\n",
    "RUN mkdir -p opt/rossmann\n",
    "COPY requirements.txt opt/rossmann/\n",
    "ENV PYTHONPATH=/home/rossmann\n",
    "\n",
    "RUN conda create -n rossmann python=3.7 --yes\n",
    "\n",
    "RUN source activate rossmann && \\\n",
    "    pip install -r opt/rossmann/requirements.txt \\\n",
    "    && source deactivate\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration, DataReferenceConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir='rossmann-store-sales/source'\n",
    "\n",
    "run_config = RunConfiguration(framework=\"Python\")\n",
    "\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "run_config.auto_prepare_environment = False\n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "cd = CondaDependencies(conda_dependencies_file_path='environment.yml')\n",
    "\n",
    "run_config.environment.python.conda_dependencies = cd\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                                path_on_datastore=data_dir, \n",
    "                                mode='download',\n",
    "                                overwrite=True)\n",
    "\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory='./', \n",
    "                                    script='./train/model_01.py',\n",
    "                                    arguments=['--data_dir', str(ds.as_download()), \n",
    "                                               '--max_pdq', '6', '1', '4',\n",
    "                                               '--n_stores', '4'],\n",
    "                                    run_config=run_config)\n",
    "\n",
    "run = exp.submit(script_run_config)\n",
    "run.log('comment', 'test local run with remotely stored data; use conda environment (autoprepare)')\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Train on a remote machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amlcompute\n",
      "arguments\n",
      "auto_prepare_environment\n",
      "communicator\n",
      "data\n",
      "data_references\n",
      "delete\n",
      "environment\n",
      "framework\n",
      "hdi\n",
      "history\n",
      "load\n",
      "max_run_duration_seconds\n",
      "mpi\n",
      "node_count\n",
      "save\n",
      "script\n",
      "source_directory_data_store\n",
      "spark\n",
      "target\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "elements = dir(run_config)\n",
    "for el in elements:\n",
    "    if el.startswith('_') is False:\n",
    "        print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 2.1 Use the Azure standard docker image; auto prepare env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment, ScriptRunConfig\n",
    "from azureml.core.runconfig import RunConfiguration, DataReferenceConfiguration, DEFAULT_CPU_IMAGE\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "data_dir='rossmann-store-sales/source'\n",
    "\n",
    "run_config = RunConfiguration(\"Python\")  # default arg anyway\n",
    "\n",
    "# target\n",
    "run_config.target = cpu_cluster.name  # check if you have already created a cpu cluster and use its name\n",
    "\n",
    "# environment \n",
    "run_config.environment.python.user_managed_dependencies = False  # default value\n",
    "                                                                 # In this case a conda env will be build on the image\n",
    "                                                                 # set to True only if we want to use an env already present on the image.\n",
    "run_config.environment = Environment.from_pip_requirements('rossmann', 'requirements.txt')\n",
    "run_config.environment.python.conda_dependencies.set_python_version('3.7.5')\n",
    "\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "\n",
    "# data_references\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                                path_on_datastore=data_dir, \n",
    "                                mode='mount',\n",
    "                                overwrite=True)\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "\n",
    "# overall config\n",
    "script_run_config = ScriptRunConfig(source_directory='./', \n",
    "                                    script='./train/model_01.py',\n",
    "                                    arguments=['--data_dir', str(ds.as_download()), \n",
    "                                               '--max_pdq', '6', '1', '4',\n",
    "                                               '--n_stores', '4'],\n",
    "                                    run_config=run_config)\n",
    "\n",
    "run = exp.submit(script_run_config)\n",
    "run.log('comment', 'Run-based remote instance; Env from pip; data mounted from azure blob storage 2')\n",
    "run.wait_for_completion(show_output=True)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Use user defined  Docker image; Azure cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment, ScriptRunConfig\n",
    "from azureml.core.runconfig import RunConfiguration, DataReferenceConfiguration, DEFAULT_CPU_IMAGE\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "data_dir='rossmann-store-sales/source'\n",
    "\n",
    "run_config = RunConfiguration(\"Python\")\n",
    "\n",
    "# target\n",
    "run_config.target = cpu_cluster.name  # check if you have already created a cpu cluster and use its name\n",
    "\n",
    "# environment \n",
    "run_config.environment.python.user_managed_dependencies = True  # set to True only if we want to use an env already present on the image.\n",
    "run_config.environment.python.interpreter_path = '/opt/conda/envs/rossmann/bin/python'\n",
    "\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.base_image = \"imscientist/rossmann_img:0.2\"\n",
    "run_config.environment.docker.base_image_registry.address = \"registry.hub.docker.com\"\n",
    "run_config.environment.docker.base_image_registry.username = \"imscientist\"\n",
    "run_config.environment.docker.base_image_registry.password = os.environ[\"DOCKER_HUB_PWD\"]\n",
    "\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                                path_on_datastore=data_dir, \n",
    "                                mode='mount',\n",
    "                                overwrite=True)\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory='./', \n",
    "                                    script='./train/train_03.py',\n",
    "                                    arguments=['--data_dir', str(ds.as_download()), \n",
    "                                               '--num_boost_round', '3000',\n",
    "                                               '--early_stopping_rounds', '200'],\n",
    "                                    run_config=run_config)\n",
    "\n",
    "run = exp.submit(script_run_config)\n",
    "run.log('comment', 'model 3 (xgboost), eta=0.03 num_boost_round=3000 max_depth=10')\n",
    "run.wait_for_completion(show_output=True)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rossmann",
   "language": "python",
   "name": "rossmann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
