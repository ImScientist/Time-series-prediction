{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/A.IVA/Documents/jupyter_notebooks/coursera_and_blogs/rossmann_competition'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1 Idea f01 `https://www.kaggle.com/xwxw2929/rossmann-sales-top1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on https://www.kaggle.com/justdoit/rossmann-store-sales/xgboost-in-python-with-rmspe/code    \n",
    "Public Score :  0.11389    \n",
    "Private Validation Score :  0.096959     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\") #Needed to save figures\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "def rmspe(y, yhat):\n",
    "    return np.sqrt(np.mean((yhat/y-1) ** 2))\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    y = np.expm1(y.get_label())\n",
    "    yhat = np.expm1(yhat)\n",
    "    return \"rmspe\", rmspe(y,yhat)\n",
    "\n",
    "# Gather some features\n",
    "def build_features(features, data):\n",
    "    # remove NaNs\n",
    "    data.fillna(0, inplace=True)\n",
    "    data.loc[data.Open.isnull(), 'Open'] = 1\n",
    "    # Use some properties directly\n",
    "    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n",
    "\n",
    "    # Label encode some features\n",
    "    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n",
    "    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n",
    "    data.StoreType.replace(mappings, inplace=True)\n",
    "    data.Assortment.replace(mappings, inplace=True)\n",
    "    data.StateHoliday.replace(mappings, inplace=True)\n",
    "\n",
    "    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['DayOfWeek'] = data.Date.dt.dayofweek\n",
    "    data['WeekOfYear'] = data.Date.dt.weekofyear\n",
    "\n",
    "    # CompetionOpen en PromoOpen from https://www.kaggle.com/ananya77041/rossmann-store-sales/randomforestpython/code\n",
    "    # Calculate time competition open time in months\n",
    "    features.append('CompetitionOpen')\n",
    "    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n",
    "        (data.Month - data.CompetitionOpenSinceMonth)\n",
    "    # Promo open time in months\n",
    "    features.append('PromoOpen')\n",
    "    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n",
    "        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n",
    "    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n",
    "    data.loc[data.Promo2SinceYear == 0, 'PromoOpen'] = 0\n",
    "\n",
    "    # Indicate that sales on that day are in promo interval\n",
    "    features.append('IsPromoMonth')\n",
    "    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n",
    "             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "    data['monthStr'] = data.Month.map(month2str)\n",
    "    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n",
    "    data['IsPromoMonth'] = 0\n",
    "    for interval in data.PromoInterval.unique():\n",
    "        if interval != '':\n",
    "            for month in interval.split(','):\n",
    "                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', 'data', 'rossmann-store-sales', 'source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the training, test and store data using pandas\n",
      "Assume store open, if not provided\n",
      "Consider only open stores for training. Closed stores wont count into the score.\n",
      "Use only Sales bigger then zero. Simplifies calculation of rmspe\n",
      "Join with store\n",
      "augment features\n",
      "['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday', 'StoreType', 'Assortment', 'StateHoliday', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n",
      "training data processed\n"
     ]
    }
   ],
   "source": [
    "print(\"Load the training, test and store data using pandas\")\n",
    "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
    "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
    "         'StateHoliday': np.dtype(str),\n",
    "         'Promo2SinceWeek': np.dtype(int),\n",
    "         'SchoolHoliday': np.dtype(float),\n",
    "         'PromoInterval': np.dtype(str)}\n",
    "train = pd.read_csv(os.path.join(data_dir, \"train.csv\"), parse_dates=[2], dtype=types)\n",
    "test = pd.read_csv(os.path.join(data_dir, \"test.csv\"), parse_dates=[3], dtype=types)\n",
    "store = pd.read_csv(os.path.join(data_dir, \"store.csv\"))\n",
    "\n",
    "print(\"Assume store open, if not provided\")\n",
    "train.fillna(1, inplace=True)\n",
    "test.fillna(1, inplace=True)\n",
    "\n",
    "print(\"Consider only open stores for training. Closed stores wont count into the score.\")\n",
    "train = train[train[\"Open\"] != 0]\n",
    "print(\"Use only Sales bigger then zero. Simplifies calculation of rmspe\")\n",
    "train = train[train[\"Sales\"] > 0]\n",
    "\n",
    "print(\"Join with store\")\n",
    "train = pd.merge(train, store, on='Store')\n",
    "test = pd.merge(test, store, on='Store')\n",
    "\n",
    "features = []\n",
    "\n",
    "print(\"augment features\")\n",
    "build_features(features, train)\n",
    "build_features([], test)\n",
    "print(features)\n",
    "\n",
    "print('training data processed')\n",
    "\n",
    "params = {\"objective\": \"reg:squarederror\",\n",
    "          \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 10,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 1301\n",
    "          }\n",
    "num_boost_round = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>...</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>CompetitionOpen</th>\n",
       "      <th>PromoOpen</th>\n",
       "      <th>monthStr</th>\n",
       "      <th>IsPromoMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-07-30</td>\n",
       "      <td>5020</td>\n",
       "      <td>546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          4 2015-07-31   5263        555     1      1            0   \n",
       "1      1          3 2015-07-30   5020        546     1      1            0   \n",
       "\n",
       "   SchoolHoliday  StoreType  ... Promo2SinceYear  PromoInterval  Year  Month  \\\n",
       "0            1.0          3  ...             0.0                 2015      7   \n",
       "1            1.0          3  ...             0.0                 2015      7   \n",
       "\n",
       "   Day  WeekOfYear  CompetitionOpen PromoOpen  monthStr  IsPromoMonth  \n",
       "0   31          31             82.0       0.0       Jul             0  \n",
       "1   30          31             82.0       0.0       Jul             0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train['StateHoliday'] = train['StateHoliday'].astype(int)\n",
    "train['Assortment'] = train['Assortment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a XGBoost model\n",
      "[0]\ttrain-rmse:5.79377\teval-rmse:5.79408\ttrain-rmspe:0.99684\teval-rmspe:0.996841\n",
      "Multiple eval metrics have been passed: 'eval-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmspe hasn't improved in 100 rounds.\n",
      "[1]\ttrain-rmse:4.06353\teval-rmse:4.06502\ttrain-rmspe:0.981462\teval-rmspe:0.981484\n",
      "[2]\ttrain-rmse:2.85371\teval-rmse:2.85572\ttrain-rmspe:0.938004\teval-rmspe:0.938079\n",
      "[3]\ttrain-rmse:2.00973\teval-rmse:2.0122\ttrain-rmspe:0.856688\teval-rmspe:0.856823\n",
      "[4]\ttrain-rmse:1.42415\teval-rmse:1.42679\ttrain-rmspe:0.743816\teval-rmspe:0.743606\n",
      "[5]\ttrain-rmse:1.01979\teval-rmse:1.02292\ttrain-rmspe:0.619458\teval-rmspe:0.618166\n",
      "[6]\ttrain-rmse:0.743183\teval-rmse:0.746465\ttrain-rmspe:0.504781\teval-rmspe:0.50062\n",
      "[7]\ttrain-rmse:0.555348\teval-rmse:0.558586\ttrain-rmspe:0.412774\teval-rmspe:0.404574\n",
      "[8]\ttrain-rmse:0.436654\teval-rmse:0.439691\ttrain-rmspe:0.352529\teval-rmspe:0.33875\n",
      "[9]\ttrain-rmse:0.364029\teval-rmse:0.366774\ttrain-rmspe:0.320635\teval-rmspe:0.300824\n",
      "[10]\ttrain-rmse:0.321428\teval-rmse:0.323532\ttrain-rmspe:0.30826\teval-rmspe:0.283367\n",
      "[11]\ttrain-rmse:0.290535\teval-rmse:0.292033\ttrain-rmspe:0.293912\teval-rmspe:0.270841\n",
      "[12]\ttrain-rmse:0.267887\teval-rmse:0.269516\ttrain-rmspe:0.286145\teval-rmspe:0.26068\n",
      "[13]\ttrain-rmse:0.254879\teval-rmse:0.256497\ttrain-rmspe:0.28388\teval-rmspe:0.256757\n",
      "[14]\ttrain-rmse:0.238283\teval-rmse:0.23948\ttrain-rmspe:0.274567\teval-rmspe:0.24555\n",
      "[15]\ttrain-rmse:0.234748\teval-rmse:0.235773\ttrain-rmspe:0.276569\teval-rmspe:0.24622\n",
      "[16]\ttrain-rmse:0.228406\teval-rmse:0.22923\ttrain-rmspe:0.273748\teval-rmspe:0.241669\n",
      "[17]\ttrain-rmse:0.21605\teval-rmse:0.216216\ttrain-rmspe:0.261761\teval-rmspe:0.228866\n",
      "[18]\ttrain-rmse:0.21112\teval-rmse:0.211253\ttrain-rmspe:0.250236\teval-rmspe:0.224814\n",
      "[19]\ttrain-rmse:0.19651\teval-rmse:0.196453\ttrain-rmspe:0.23567\teval-rmspe:0.20839\n",
      "[20]\ttrain-rmse:0.192111\teval-rmse:0.191854\ttrain-rmspe:0.232496\teval-rmspe:0.203743\n",
      "[21]\ttrain-rmse:0.190218\teval-rmse:0.190016\ttrain-rmspe:0.231153\teval-rmspe:0.202437\n",
      "[22]\ttrain-rmse:0.188048\teval-rmse:0.187997\ttrain-rmspe:0.22909\teval-rmspe:0.200537\n",
      "[23]\ttrain-rmse:0.183294\teval-rmse:0.183171\ttrain-rmspe:0.225044\teval-rmspe:0.195372\n",
      "[24]\ttrain-rmse:0.180082\teval-rmse:0.18027\ttrain-rmspe:0.221015\teval-rmspe:0.192562\n",
      "[25]\ttrain-rmse:0.179075\teval-rmse:0.179372\ttrain-rmspe:0.220021\teval-rmspe:0.191759\n",
      "[26]\ttrain-rmse:0.173313\teval-rmse:0.174081\ttrain-rmspe:0.214449\teval-rmspe:0.186239\n",
      "[27]\ttrain-rmse:0.170728\teval-rmse:0.171427\ttrain-rmspe:0.211983\teval-rmspe:0.182729\n",
      "[28]\ttrain-rmse:0.160556\teval-rmse:0.161091\ttrain-rmspe:0.20298\teval-rmspe:0.171739\n",
      "[29]\ttrain-rmse:0.157292\teval-rmse:0.157884\ttrain-rmspe:0.199907\teval-rmspe:0.168242\n",
      "[30]\ttrain-rmse:0.155717\teval-rmse:0.156363\ttrain-rmspe:0.198245\teval-rmspe:0.166691\n",
      "[31]\ttrain-rmse:0.152598\teval-rmse:0.153454\ttrain-rmspe:0.195662\teval-rmspe:0.163722\n",
      "[32]\ttrain-rmse:0.149935\teval-rmse:0.150941\ttrain-rmspe:0.192468\teval-rmspe:0.161096\n",
      "[33]\ttrain-rmse:0.149015\teval-rmse:0.150221\ttrain-rmspe:0.1914\teval-rmspe:0.160371\n",
      "[34]\ttrain-rmse:0.1474\teval-rmse:0.148566\ttrain-rmspe:0.190003\teval-rmspe:0.158709\n",
      "[35]\ttrain-rmse:0.14652\teval-rmse:0.14781\ttrain-rmspe:0.189227\teval-rmspe:0.15796\n",
      "[36]\ttrain-rmse:0.145935\teval-rmse:0.147243\ttrain-rmspe:0.186432\teval-rmspe:0.157412\n",
      "[37]\ttrain-rmse:0.144888\teval-rmse:0.146292\ttrain-rmspe:0.185678\teval-rmspe:0.156405\n",
      "[38]\ttrain-rmse:0.144164\teval-rmse:0.145663\ttrain-rmspe:0.184878\teval-rmspe:0.15576\n",
      "[39]\ttrain-rmse:0.143501\teval-rmse:0.145134\ttrain-rmspe:0.183985\teval-rmspe:0.155169\n",
      "[40]\ttrain-rmse:0.140483\teval-rmse:0.141938\ttrain-rmspe:0.181379\teval-rmspe:0.151849\n",
      "[41]\ttrain-rmse:0.138432\teval-rmse:0.140018\ttrain-rmspe:0.179489\teval-rmspe:0.149775\n",
      "[42]\ttrain-rmse:0.136509\teval-rmse:0.138141\ttrain-rmspe:0.177633\teval-rmspe:0.147549\n",
      "[43]\ttrain-rmse:0.135686\teval-rmse:0.137352\ttrain-rmspe:0.176922\teval-rmspe:0.146707\n",
      "[44]\ttrain-rmse:0.13408\teval-rmse:0.135554\ttrain-rmspe:0.175567\teval-rmspe:0.144789\n",
      "[45]\ttrain-rmse:0.132466\teval-rmse:0.134007\ttrain-rmspe:0.173939\teval-rmspe:0.14309\n",
      "[46]\ttrain-rmse:0.131736\teval-rmse:0.133292\ttrain-rmspe:0.173397\teval-rmspe:0.142353\n",
      "[47]\ttrain-rmse:0.130636\teval-rmse:0.132273\ttrain-rmspe:0.171653\teval-rmspe:0.14121\n",
      "[48]\ttrain-rmse:0.129465\teval-rmse:0.131048\ttrain-rmspe:0.170662\teval-rmspe:0.139805\n",
      "[49]\ttrain-rmse:0.129143\teval-rmse:0.130775\ttrain-rmspe:0.170038\teval-rmspe:0.139543\n",
      "[50]\ttrain-rmse:0.128126\teval-rmse:0.129881\ttrain-rmspe:0.168585\teval-rmspe:0.138423\n",
      "[51]\ttrain-rmse:0.126771\teval-rmse:0.128756\ttrain-rmspe:0.167346\teval-rmspe:0.137268\n",
      "[52]\ttrain-rmse:0.124688\teval-rmse:0.126721\ttrain-rmspe:0.165464\teval-rmspe:0.13501\n",
      "[53]\ttrain-rmse:0.124074\teval-rmse:0.126207\ttrain-rmspe:0.150151\teval-rmspe:0.13447\n",
      "[54]\ttrain-rmse:0.1219\teval-rmse:0.12426\ttrain-rmspe:0.147983\teval-rmspe:0.132295\n",
      "[55]\ttrain-rmse:0.121597\teval-rmse:0.124049\ttrain-rmspe:0.147618\teval-rmspe:0.132024\n",
      "[56]\ttrain-rmse:0.120844\teval-rmse:0.12346\ttrain-rmspe:0.146817\teval-rmspe:0.131375\n",
      "[57]\ttrain-rmse:0.12031\teval-rmse:0.123047\ttrain-rmspe:0.146177\teval-rmspe:0.130937\n",
      "[58]\ttrain-rmse:0.118825\teval-rmse:0.121633\ttrain-rmspe:0.144624\teval-rmspe:0.129393\n",
      "[59]\ttrain-rmse:0.118651\teval-rmse:0.121484\ttrain-rmspe:0.143993\teval-rmspe:0.129219\n",
      "[60]\ttrain-rmse:0.11815\teval-rmse:0.121022\ttrain-rmspe:0.143493\teval-rmspe:0.128763\n",
      "[61]\ttrain-rmse:0.117562\teval-rmse:0.120518\ttrain-rmspe:0.142934\teval-rmspe:0.128288\n",
      "[62]\ttrain-rmse:0.117001\teval-rmse:0.120009\ttrain-rmspe:0.141765\teval-rmspe:0.127791\n",
      "[63]\ttrain-rmse:0.11627\teval-rmse:0.119268\ttrain-rmspe:0.141026\teval-rmspe:0.126972\n",
      "[64]\ttrain-rmse:0.115065\teval-rmse:0.11808\ttrain-rmspe:0.13977\teval-rmspe:0.125702\n",
      "[65]\ttrain-rmse:0.11474\teval-rmse:0.117751\ttrain-rmspe:0.139444\teval-rmspe:0.12528\n",
      "[66]\ttrain-rmse:0.114126\teval-rmse:0.117248\ttrain-rmspe:0.137693\teval-rmspe:0.124705\n",
      "[67]\ttrain-rmse:0.11393\teval-rmse:0.117126\ttrain-rmspe:0.137441\teval-rmspe:0.124583\n",
      "[68]\ttrain-rmse:0.112501\teval-rmse:0.115689\ttrain-rmspe:0.136092\teval-rmspe:0.123066\n",
      "[69]\ttrain-rmse:0.111373\teval-rmse:0.114686\ttrain-rmspe:0.13498\teval-rmspe:0.121888\n",
      "[70]\ttrain-rmse:0.110926\teval-rmse:0.114525\ttrain-rmspe:0.134185\teval-rmspe:0.121685\n",
      "[71]\ttrain-rmse:0.110232\teval-rmse:0.113968\ttrain-rmspe:0.133483\teval-rmspe:0.121052\n",
      "[72]\ttrain-rmse:0.109957\teval-rmse:0.113774\ttrain-rmspe:0.133178\teval-rmspe:0.12087\n",
      "[73]\ttrain-rmse:0.109411\teval-rmse:0.113361\ttrain-rmspe:0.132647\teval-rmspe:0.120263\n",
      "[74]\ttrain-rmse:0.108652\teval-rmse:0.11283\ttrain-rmspe:0.131679\teval-rmspe:0.119662\n",
      "[75]\ttrain-rmse:0.108296\teval-rmse:0.112522\ttrain-rmspe:0.130536\teval-rmspe:0.119159\n",
      "[76]\ttrain-rmse:0.107694\teval-rmse:0.11212\ttrain-rmspe:0.12971\teval-rmspe:0.118723\n",
      "[77]\ttrain-rmse:0.107225\teval-rmse:0.111733\ttrain-rmspe:0.129252\teval-rmspe:0.118354\n",
      "[78]\ttrain-rmse:0.106844\teval-rmse:0.111386\ttrain-rmspe:0.128755\teval-rmspe:0.117988\n",
      "[79]\ttrain-rmse:0.106284\teval-rmse:0.110855\ttrain-rmspe:0.128073\teval-rmspe:0.117378\n",
      "[80]\ttrain-rmse:0.10596\teval-rmse:0.110585\ttrain-rmspe:0.127761\teval-rmspe:0.1171\n",
      "[81]\ttrain-rmse:0.105201\teval-rmse:0.109819\ttrain-rmspe:0.127056\teval-rmspe:0.116128\n",
      "[82]\ttrain-rmse:0.104564\teval-rmse:0.10925\ttrain-rmspe:0.126353\teval-rmspe:0.115507\n",
      "[83]\ttrain-rmse:0.104198\teval-rmse:0.108947\ttrain-rmspe:0.126007\teval-rmspe:0.115189\n",
      "[84]\ttrain-rmse:0.104067\teval-rmse:0.108838\ttrain-rmspe:0.125889\teval-rmspe:0.115083\n",
      "[85]\ttrain-rmse:0.103825\teval-rmse:0.108629\ttrain-rmspe:0.125594\teval-rmspe:0.114858\n",
      "[86]\ttrain-rmse:0.103345\teval-rmse:0.108215\ttrain-rmspe:0.125201\teval-rmspe:0.114455\n",
      "[87]\ttrain-rmse:0.103026\teval-rmse:0.108016\ttrain-rmspe:0.124692\teval-rmspe:0.114285\n",
      "[88]\ttrain-rmse:0.102678\teval-rmse:0.107746\ttrain-rmspe:0.124348\teval-rmspe:0.114\n",
      "[89]\ttrain-rmse:0.102323\teval-rmse:0.107475\ttrain-rmspe:0.124003\teval-rmspe:0.113704\n",
      "[90]\ttrain-rmse:0.101976\teval-rmse:0.107245\ttrain-rmspe:0.123687\teval-rmspe:0.113429\n",
      "[91]\ttrain-rmse:0.101705\teval-rmse:0.107102\ttrain-rmspe:0.123383\teval-rmspe:0.113275\n",
      "[92]\ttrain-rmse:0.101365\teval-rmse:0.106817\ttrain-rmspe:0.122912\teval-rmspe:0.112964\n",
      "[93]\ttrain-rmse:0.100953\teval-rmse:0.106531\ttrain-rmspe:0.122307\teval-rmspe:0.112539\n",
      "[94]\ttrain-rmse:0.100649\teval-rmse:0.106322\ttrain-rmspe:0.121871\teval-rmspe:0.112333\n",
      "[95]\ttrain-rmse:0.100455\teval-rmse:0.106183\ttrain-rmspe:0.121658\teval-rmspe:0.112186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttrain-rmse:0.100283\teval-rmse:0.106113\ttrain-rmspe:0.121369\teval-rmspe:0.11208\n",
      "[97]\ttrain-rmse:0.10008\teval-rmse:0.105962\ttrain-rmspe:0.12118\teval-rmspe:0.111944\n",
      "[98]\ttrain-rmse:0.099647\teval-rmse:0.105611\ttrain-rmspe:0.12079\teval-rmspe:0.111545\n",
      "[99]\ttrain-rmse:0.09952\teval-rmse:0.105499\ttrain-rmspe:0.120676\teval-rmspe:0.111438\n",
      "[100]\ttrain-rmse:0.099342\teval-rmse:0.105325\ttrain-rmspe:0.120509\teval-rmspe:0.111111\n",
      "[101]\ttrain-rmse:0.099118\teval-rmse:0.105145\ttrain-rmspe:0.118589\teval-rmspe:0.110912\n",
      "[102]\ttrain-rmse:0.098825\teval-rmse:0.104926\ttrain-rmspe:0.118301\teval-rmspe:0.110709\n",
      "[103]\ttrain-rmse:0.098477\teval-rmse:0.104685\ttrain-rmspe:0.117965\teval-rmspe:0.110434\n",
      "[104]\ttrain-rmse:0.097956\teval-rmse:0.104264\ttrain-rmspe:0.117506\teval-rmspe:0.109986\n",
      "[105]\ttrain-rmse:0.097587\teval-rmse:0.103986\ttrain-rmspe:0.117133\teval-rmspe:0.109681\n",
      "[106]\ttrain-rmse:0.097222\teval-rmse:0.10365\ttrain-rmspe:0.116642\teval-rmspe:0.109346\n",
      "[107]\ttrain-rmse:0.096864\teval-rmse:0.103382\ttrain-rmspe:0.116289\teval-rmspe:0.109068\n",
      "[108]\ttrain-rmse:0.096809\teval-rmse:0.103354\ttrain-rmspe:0.116243\teval-rmspe:0.109039\n",
      "[109]\ttrain-rmse:0.09636\teval-rmse:0.10297\ttrain-rmspe:0.115803\teval-rmspe:0.108578\n",
      "[110]\ttrain-rmse:0.096272\teval-rmse:0.102948\ttrain-rmspe:0.115721\teval-rmspe:0.10857\n",
      "[111]\ttrain-rmse:0.096002\teval-rmse:0.102772\ttrain-rmspe:0.115428\teval-rmspe:0.108391\n",
      "[112]\ttrain-rmse:0.095813\teval-rmse:0.102693\ttrain-rmspe:0.115129\teval-rmspe:0.108313\n",
      "[113]\ttrain-rmse:0.09538\teval-rmse:0.102258\ttrain-rmspe:0.114701\teval-rmspe:0.107788\n",
      "[114]\ttrain-rmse:0.095163\teval-rmse:0.10209\ttrain-rmspe:0.113737\teval-rmspe:0.10762\n",
      "[115]\ttrain-rmse:0.094627\teval-rmse:0.101421\ttrain-rmspe:0.112697\teval-rmspe:0.106454\n",
      "[116]\ttrain-rmse:0.094371\teval-rmse:0.101242\ttrain-rmspe:0.112621\teval-rmspe:0.106265\n",
      "[117]\ttrain-rmse:0.094195\teval-rmse:0.101149\ttrain-rmspe:0.112426\teval-rmspe:0.106197\n",
      "[118]\ttrain-rmse:0.093974\teval-rmse:0.100956\ttrain-rmspe:0.112217\teval-rmspe:0.105972\n",
      "[119]\ttrain-rmse:0.093717\teval-rmse:0.100745\ttrain-rmspe:0.111951\teval-rmspe:0.105677\n",
      "[120]\ttrain-rmse:0.093538\teval-rmse:0.10063\ttrain-rmspe:0.111758\teval-rmspe:0.105544\n",
      "[121]\ttrain-rmse:0.093437\teval-rmse:0.100586\ttrain-rmspe:0.111525\teval-rmspe:0.105503\n",
      "[122]\ttrain-rmse:0.093365\teval-rmse:0.100538\ttrain-rmspe:0.111445\teval-rmspe:0.105461\n",
      "[123]\ttrain-rmse:0.093251\teval-rmse:0.100494\ttrain-rmspe:0.111317\teval-rmspe:0.105389\n",
      "[124]\ttrain-rmse:0.09306\teval-rmse:0.100367\ttrain-rmspe:0.111114\teval-rmspe:0.105214\n",
      "[125]\ttrain-rmse:0.09288\teval-rmse:0.100228\ttrain-rmspe:0.110957\teval-rmspe:0.105069\n",
      "[126]\ttrain-rmse:0.092725\teval-rmse:0.100136\ttrain-rmspe:0.110808\teval-rmspe:0.104979\n",
      "[127]\ttrain-rmse:0.092641\teval-rmse:0.100102\ttrain-rmspe:0.110727\teval-rmspe:0.104946\n",
      "[128]\ttrain-rmse:0.092604\teval-rmse:0.100092\ttrain-rmspe:0.110695\teval-rmspe:0.104936\n",
      "[129]\ttrain-rmse:0.092211\teval-rmse:0.099759\ttrain-rmspe:0.110269\teval-rmspe:0.104549\n",
      "[130]\ttrain-rmse:0.092016\teval-rmse:0.099647\ttrain-rmspe:0.109944\teval-rmspe:0.104433\n",
      "[131]\ttrain-rmse:0.091776\teval-rmse:0.099501\ttrain-rmspe:0.109719\teval-rmspe:0.104297\n",
      "[132]\ttrain-rmse:0.091536\teval-rmse:0.09937\ttrain-rmspe:0.109499\teval-rmspe:0.10417\n",
      "[133]\ttrain-rmse:0.091272\teval-rmse:0.099095\ttrain-rmspe:0.109245\teval-rmspe:0.103851\n",
      "[134]\ttrain-rmse:0.09111\teval-rmse:0.09903\ttrain-rmspe:0.10903\teval-rmspe:0.103787\n",
      "[135]\ttrain-rmse:0.090955\teval-rmse:0.098949\ttrain-rmspe:0.108834\teval-rmspe:0.103683\n",
      "[136]\ttrain-rmse:0.090757\teval-rmse:0.098818\ttrain-rmspe:0.108598\teval-rmspe:0.103555\n",
      "[137]\ttrain-rmse:0.090612\teval-rmse:0.098734\ttrain-rmspe:0.108439\teval-rmspe:0.103437\n",
      "[138]\ttrain-rmse:0.090506\teval-rmse:0.098678\ttrain-rmspe:0.108334\teval-rmspe:0.103365\n",
      "[139]\ttrain-rmse:0.090311\teval-rmse:0.098542\ttrain-rmspe:0.108096\teval-rmspe:0.103227\n",
      "[140]\ttrain-rmse:0.090152\teval-rmse:0.098443\ttrain-rmspe:0.107652\teval-rmspe:0.103134\n",
      "[141]\ttrain-rmse:0.090041\teval-rmse:0.098375\ttrain-rmspe:0.104675\teval-rmspe:0.103067\n",
      "[142]\ttrain-rmse:0.089947\teval-rmse:0.098332\ttrain-rmspe:0.104561\teval-rmspe:0.103031\n",
      "[143]\ttrain-rmse:0.089831\teval-rmse:0.098205\ttrain-rmspe:0.104397\teval-rmspe:0.102787\n",
      "[144]\ttrain-rmse:0.089688\teval-rmse:0.098107\ttrain-rmspe:0.104255\teval-rmspe:0.102687\n",
      "[145]\ttrain-rmse:0.089607\teval-rmse:0.098044\ttrain-rmspe:0.104176\teval-rmspe:0.102609\n",
      "[146]\ttrain-rmse:0.089531\teval-rmse:0.097992\ttrain-rmspe:0.104094\teval-rmspe:0.10255\n",
      "[147]\ttrain-rmse:0.089396\teval-rmse:0.097896\ttrain-rmspe:0.103948\teval-rmspe:0.102483\n",
      "[148]\ttrain-rmse:0.089289\teval-rmse:0.097869\ttrain-rmspe:0.103841\teval-rmspe:0.102465\n",
      "[149]\ttrain-rmse:0.089041\teval-rmse:0.097667\ttrain-rmspe:0.103608\teval-rmspe:0.102255\n",
      "[150]\ttrain-rmse:0.088915\teval-rmse:0.097625\ttrain-rmspe:0.103479\teval-rmspe:0.102219\n",
      "[151]\ttrain-rmse:0.08872\teval-rmse:0.097535\ttrain-rmspe:0.10291\teval-rmspe:0.10213\n",
      "[152]\ttrain-rmse:0.08862\teval-rmse:0.097494\ttrain-rmspe:0.102821\teval-rmspe:0.102087\n",
      "[153]\ttrain-rmse:0.088494\teval-rmse:0.097409\ttrain-rmspe:0.102717\teval-rmspe:0.102022\n",
      "[154]\ttrain-rmse:0.088331\teval-rmse:0.097324\ttrain-rmspe:0.100007\teval-rmspe:0.101933\n",
      "[155]\ttrain-rmse:0.088152\teval-rmse:0.097188\ttrain-rmspe:0.099793\teval-rmspe:0.10177\n",
      "[156]\ttrain-rmse:0.08808\teval-rmse:0.097142\ttrain-rmspe:0.099689\teval-rmspe:0.101744\n",
      "[157]\ttrain-rmse:0.087868\teval-rmse:0.097021\ttrain-rmspe:0.099486\teval-rmspe:0.101621\n",
      "[158]\ttrain-rmse:0.087769\teval-rmse:0.096963\ttrain-rmspe:0.099387\teval-rmspe:0.101565\n",
      "[159]\ttrain-rmse:0.087559\teval-rmse:0.096861\ttrain-rmspe:0.099157\teval-rmspe:0.101461\n",
      "[160]\ttrain-rmse:0.087478\teval-rmse:0.096817\ttrain-rmspe:0.099079\teval-rmspe:0.101416\n",
      "[161]\ttrain-rmse:0.087328\teval-rmse:0.096762\ttrain-rmspe:0.098939\teval-rmspe:0.10138\n",
      "[162]\ttrain-rmse:0.087197\teval-rmse:0.096727\ttrain-rmspe:0.098831\teval-rmspe:0.101351\n",
      "[163]\ttrain-rmse:0.087075\teval-rmse:0.096675\ttrain-rmspe:0.098713\teval-rmspe:0.101299\n",
      "[164]\ttrain-rmse:0.086863\teval-rmse:0.096535\ttrain-rmspe:0.09845\teval-rmspe:0.101073\n",
      "[165]\ttrain-rmse:0.086764\teval-rmse:0.096484\ttrain-rmspe:0.09832\teval-rmspe:0.101042\n",
      "[166]\ttrain-rmse:0.0867\teval-rmse:0.096436\ttrain-rmspe:0.098255\teval-rmspe:0.100993\n",
      "[167]\ttrain-rmse:0.086602\teval-rmse:0.096395\ttrain-rmspe:0.09814\teval-rmspe:0.100961\n",
      "[168]\ttrain-rmse:0.086398\teval-rmse:0.09629\ttrain-rmspe:0.097877\teval-rmspe:0.100837\n",
      "[169]\ttrain-rmse:0.086278\teval-rmse:0.096228\ttrain-rmspe:0.097765\teval-rmspe:0.10079\n",
      "[170]\ttrain-rmse:0.086142\teval-rmse:0.096194\ttrain-rmspe:0.097409\teval-rmspe:0.100761\n",
      "[171]\ttrain-rmse:0.086009\teval-rmse:0.096107\ttrain-rmspe:0.097257\teval-rmspe:0.100691\n",
      "[172]\ttrain-rmse:0.08586\teval-rmse:0.09597\ttrain-rmspe:0.097089\teval-rmspe:0.10046\n",
      "[173]\ttrain-rmse:0.085746\teval-rmse:0.095872\ttrain-rmspe:0.096946\teval-rmspe:0.100334\n",
      "[174]\ttrain-rmse:0.085589\teval-rmse:0.095753\ttrain-rmspe:0.096783\teval-rmspe:0.100204\n",
      "[175]\ttrain-rmse:0.08548\teval-rmse:0.095711\ttrain-rmspe:0.096673\teval-rmspe:0.100168\n",
      "[176]\ttrain-rmse:0.085353\teval-rmse:0.0957\ttrain-rmspe:0.09653\teval-rmspe:0.100177\n",
      "[177]\ttrain-rmse:0.085265\teval-rmse:0.095644\ttrain-rmspe:0.096448\teval-rmspe:0.100115\n",
      "[178]\ttrain-rmse:0.085025\teval-rmse:0.095506\ttrain-rmspe:0.095971\teval-rmspe:0.099924\n",
      "[179]\ttrain-rmse:0.084865\teval-rmse:0.095452\ttrain-rmspe:0.095795\teval-rmspe:0.09988\n",
      "[180]\ttrain-rmse:0.084741\teval-rmse:0.095396\ttrain-rmspe:0.095638\teval-rmspe:0.0998\n",
      "[181]\ttrain-rmse:0.084612\teval-rmse:0.095347\ttrain-rmspe:0.09372\teval-rmspe:0.099741\n",
      "[182]\ttrain-rmse:0.084495\teval-rmse:0.095255\ttrain-rmspe:0.093572\teval-rmspe:0.099653\n",
      "[183]\ttrain-rmse:0.084412\teval-rmse:0.09522\ttrain-rmspe:0.093473\teval-rmspe:0.099616\n",
      "[184]\ttrain-rmse:0.084176\teval-rmse:0.095074\ttrain-rmspe:0.093229\teval-rmspe:0.099445\n",
      "[185]\ttrain-rmse:0.084031\teval-rmse:0.094993\ttrain-rmspe:0.093067\teval-rmspe:0.099358\n",
      "[186]\ttrain-rmse:0.083923\teval-rmse:0.094925\ttrain-rmspe:0.092949\teval-rmspe:0.09928\n",
      "[187]\ttrain-rmse:0.083748\teval-rmse:0.094903\ttrain-rmspe:0.092214\teval-rmspe:0.09924\n",
      "[188]\ttrain-rmse:0.0836\teval-rmse:0.094872\ttrain-rmspe:0.09197\teval-rmspe:0.099204\n",
      "[189]\ttrain-rmse:0.083386\teval-rmse:0.094736\ttrain-rmspe:0.09174\teval-rmspe:0.099066\n",
      "[190]\ttrain-rmse:0.083261\teval-rmse:0.094671\ttrain-rmspe:0.091578\teval-rmspe:0.098996\n",
      "[191]\ttrain-rmse:0.083183\teval-rmse:0.094593\ttrain-rmspe:0.091496\teval-rmspe:0.098886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\ttrain-rmse:0.083095\teval-rmse:0.094592\ttrain-rmspe:0.091397\teval-rmspe:0.09889\n",
      "[193]\ttrain-rmse:0.082988\teval-rmse:0.094531\ttrain-rmspe:0.091251\teval-rmspe:0.098829\n",
      "[194]\ttrain-rmse:0.082916\teval-rmse:0.09446\ttrain-rmspe:0.091166\teval-rmspe:0.098754\n",
      "[195]\ttrain-rmse:0.082802\teval-rmse:0.094443\ttrain-rmspe:0.091049\teval-rmspe:0.098732\n",
      "[196]\ttrain-rmse:0.08268\teval-rmse:0.094401\ttrain-rmspe:0.090821\teval-rmspe:0.098704\n",
      "[197]\ttrain-rmse:0.082589\teval-rmse:0.094326\ttrain-rmspe:0.090736\teval-rmspe:0.098604\n",
      "[198]\ttrain-rmse:0.082479\teval-rmse:0.094316\ttrain-rmspe:0.090623\teval-rmspe:0.098588\n",
      "[199]\ttrain-rmse:0.082382\teval-rmse:0.094267\ttrain-rmspe:0.090531\teval-rmspe:0.098552\n",
      "[200]\ttrain-rmse:0.082305\teval-rmse:0.094238\ttrain-rmspe:0.090448\teval-rmspe:0.098546\n",
      "[201]\ttrain-rmse:0.08216\teval-rmse:0.094119\ttrain-rmspe:0.090315\teval-rmspe:0.098425\n",
      "[202]\ttrain-rmse:0.082066\teval-rmse:0.094059\ttrain-rmspe:0.090219\teval-rmspe:0.098363\n",
      "[203]\ttrain-rmse:0.081991\teval-rmse:0.094009\ttrain-rmspe:0.090142\teval-rmspe:0.09831\n",
      "[204]\ttrain-rmse:0.081882\teval-rmse:0.09398\ttrain-rmspe:0.08974\teval-rmspe:0.098281\n",
      "[205]\ttrain-rmse:0.081828\teval-rmse:0.093955\ttrain-rmspe:0.089664\teval-rmspe:0.098263\n",
      "[206]\ttrain-rmse:0.081667\teval-rmse:0.093911\ttrain-rmspe:0.089504\teval-rmspe:0.09823\n",
      "[207]\ttrain-rmse:0.081571\teval-rmse:0.093874\ttrain-rmspe:0.089411\teval-rmspe:0.098201\n",
      "[208]\ttrain-rmse:0.081524\teval-rmse:0.093859\ttrain-rmspe:0.089362\teval-rmspe:0.098182\n",
      "[209]\ttrain-rmse:0.081431\teval-rmse:0.093869\ttrain-rmspe:0.089259\teval-rmspe:0.09819\n",
      "[210]\ttrain-rmse:0.081324\teval-rmse:0.093821\ttrain-rmspe:0.089124\teval-rmspe:0.098147\n",
      "[211]\ttrain-rmse:0.081254\teval-rmse:0.093835\ttrain-rmspe:0.089034\teval-rmspe:0.098159\n",
      "[212]\ttrain-rmse:0.081141\teval-rmse:0.093738\ttrain-rmspe:0.088915\teval-rmspe:0.098058\n",
      "[213]\ttrain-rmse:0.081064\teval-rmse:0.093669\ttrain-rmspe:0.088841\teval-rmspe:0.097966\n",
      "[214]\ttrain-rmse:0.080972\teval-rmse:0.093621\ttrain-rmspe:0.088746\teval-rmspe:0.097916\n",
      "[215]\ttrain-rmse:0.080845\teval-rmse:0.093516\ttrain-rmspe:0.088622\teval-rmspe:0.097809\n",
      "[216]\ttrain-rmse:0.08078\teval-rmse:0.093522\ttrain-rmspe:0.088552\teval-rmspe:0.097802\n",
      "[217]\ttrain-rmse:0.080629\teval-rmse:0.093473\ttrain-rmspe:0.088336\teval-rmspe:0.097745\n",
      "[218]\ttrain-rmse:0.080563\teval-rmse:0.093433\ttrain-rmspe:0.088264\teval-rmspe:0.097732\n",
      "[219]\ttrain-rmse:0.080478\teval-rmse:0.093408\ttrain-rmspe:0.088167\teval-rmspe:0.097688\n",
      "[220]\ttrain-rmse:0.080378\teval-rmse:0.093378\ttrain-rmspe:0.088007\teval-rmspe:0.097663\n",
      "[221]\ttrain-rmse:0.080228\teval-rmse:0.093323\ttrain-rmspe:0.08762\teval-rmspe:0.097585\n",
      "[222]\ttrain-rmse:0.080101\teval-rmse:0.093246\ttrain-rmspe:0.087387\teval-rmspe:0.097506\n",
      "[223]\ttrain-rmse:0.079882\teval-rmse:0.093076\ttrain-rmspe:0.087163\teval-rmspe:0.097293\n",
      "[224]\ttrain-rmse:0.079833\teval-rmse:0.093051\ttrain-rmspe:0.087118\teval-rmspe:0.097267\n",
      "[225]\ttrain-rmse:0.079729\teval-rmse:0.09299\ttrain-rmspe:0.087008\teval-rmspe:0.097175\n",
      "[226]\ttrain-rmse:0.079594\teval-rmse:0.092939\ttrain-rmspe:0.086852\teval-rmspe:0.097123\n",
      "[227]\ttrain-rmse:0.079451\teval-rmse:0.092867\ttrain-rmspe:0.086653\teval-rmspe:0.097022\n",
      "[228]\ttrain-rmse:0.0794\teval-rmse:0.092874\ttrain-rmspe:0.086584\teval-rmspe:0.097023\n",
      "[229]\ttrain-rmse:0.079321\teval-rmse:0.092814\ttrain-rmspe:0.086509\teval-rmspe:0.096974\n",
      "[230]\ttrain-rmse:0.079183\teval-rmse:0.09273\ttrain-rmspe:0.086368\teval-rmspe:0.096865\n",
      "[231]\ttrain-rmse:0.079118\teval-rmse:0.092732\ttrain-rmspe:0.086273\teval-rmspe:0.096877\n",
      "[232]\ttrain-rmse:0.079076\teval-rmse:0.092726\ttrain-rmspe:0.086228\teval-rmspe:0.096865\n",
      "[233]\ttrain-rmse:0.078992\teval-rmse:0.092691\ttrain-rmspe:0.086147\teval-rmspe:0.09683\n",
      "[234]\ttrain-rmse:0.078897\teval-rmse:0.09266\ttrain-rmspe:0.08605\teval-rmspe:0.096798\n",
      "[235]\ttrain-rmse:0.078797\teval-rmse:0.092602\ttrain-rmspe:0.085286\teval-rmspe:0.096728\n",
      "[236]\ttrain-rmse:0.078706\teval-rmse:0.092555\ttrain-rmspe:0.085145\teval-rmspe:0.096679\n",
      "[237]\ttrain-rmse:0.078604\teval-rmse:0.092495\ttrain-rmspe:0.085029\teval-rmspe:0.096613\n",
      "[238]\ttrain-rmse:0.078513\teval-rmse:0.092433\ttrain-rmspe:0.084897\teval-rmspe:0.096542\n",
      "[239]\ttrain-rmse:0.078488\teval-rmse:0.092409\ttrain-rmspe:0.084869\teval-rmspe:0.096517\n",
      "[240]\ttrain-rmse:0.078394\teval-rmse:0.092398\ttrain-rmspe:0.084511\teval-rmspe:0.096514\n",
      "[241]\ttrain-rmse:0.078335\teval-rmse:0.092366\ttrain-rmspe:0.084449\teval-rmspe:0.096489\n",
      "[242]\ttrain-rmse:0.078251\teval-rmse:0.092328\ttrain-rmspe:0.084346\teval-rmspe:0.096442\n",
      "[243]\ttrain-rmse:0.078127\teval-rmse:0.092247\ttrain-rmspe:0.08421\teval-rmspe:0.096327\n",
      "[244]\ttrain-rmse:0.078047\teval-rmse:0.092232\ttrain-rmspe:0.084101\teval-rmspe:0.096324\n",
      "[245]\ttrain-rmse:0.07794\teval-rmse:0.09219\ttrain-rmspe:0.083987\teval-rmspe:0.09627\n",
      "[246]\ttrain-rmse:0.077862\teval-rmse:0.092138\ttrain-rmspe:0.08389\teval-rmspe:0.096221\n",
      "[247]\ttrain-rmse:0.07781\teval-rmse:0.092162\ttrain-rmspe:0.083834\teval-rmspe:0.096275\n",
      "[248]\ttrain-rmse:0.077731\teval-rmse:0.092148\ttrain-rmspe:0.083726\teval-rmspe:0.096286\n",
      "[249]\ttrain-rmse:0.07763\teval-rmse:0.092093\ttrain-rmspe:0.0836\teval-rmspe:0.096243\n",
      "[250]\ttrain-rmse:0.077496\teval-rmse:0.092059\ttrain-rmspe:0.083463\teval-rmspe:0.096208\n",
      "[251]\ttrain-rmse:0.077393\teval-rmse:0.092033\ttrain-rmspe:0.083335\teval-rmspe:0.096183\n",
      "[252]\ttrain-rmse:0.077315\teval-rmse:0.092001\ttrain-rmspe:0.083227\teval-rmspe:0.096154\n",
      "[253]\ttrain-rmse:0.077264\teval-rmse:0.091995\ttrain-rmspe:0.083182\teval-rmspe:0.096144\n",
      "[254]\ttrain-rmse:0.077155\teval-rmse:0.091933\ttrain-rmspe:0.083055\teval-rmspe:0.096059\n",
      "[255]\ttrain-rmse:0.077065\teval-rmse:0.091923\ttrain-rmspe:0.082948\teval-rmspe:0.096059\n",
      "[256]\ttrain-rmse:0.076944\teval-rmse:0.091885\ttrain-rmspe:0.082776\teval-rmspe:0.096017\n",
      "[257]\ttrain-rmse:0.07686\teval-rmse:0.09187\ttrain-rmspe:0.082669\teval-rmspe:0.096002\n",
      "[258]\ttrain-rmse:0.076804\teval-rmse:0.091875\ttrain-rmspe:0.082596\teval-rmspe:0.096013\n",
      "[259]\ttrain-rmse:0.076707\teval-rmse:0.091851\ttrain-rmspe:0.082501\teval-rmspe:0.09599\n",
      "[260]\ttrain-rmse:0.076638\teval-rmse:0.091816\ttrain-rmspe:0.08242\teval-rmspe:0.095955\n",
      "[261]\ttrain-rmse:0.076566\teval-rmse:0.091799\ttrain-rmspe:0.082347\teval-rmspe:0.09593\n",
      "[262]\ttrain-rmse:0.076485\teval-rmse:0.091794\ttrain-rmspe:0.082258\teval-rmspe:0.095923\n",
      "[263]\ttrain-rmse:0.076425\teval-rmse:0.091762\ttrain-rmspe:0.082184\teval-rmspe:0.095895\n",
      "[264]\ttrain-rmse:0.07633\teval-rmse:0.091749\ttrain-rmspe:0.082078\teval-rmspe:0.09589\n",
      "[265]\ttrain-rmse:0.076242\teval-rmse:0.091686\ttrain-rmspe:0.081977\teval-rmspe:0.095869\n",
      "[266]\ttrain-rmse:0.076164\teval-rmse:0.091635\ttrain-rmspe:0.081887\teval-rmspe:0.09583\n",
      "[267]\ttrain-rmse:0.076116\teval-rmse:0.091625\ttrain-rmspe:0.081837\teval-rmspe:0.095824\n",
      "[268]\ttrain-rmse:0.076054\teval-rmse:0.091606\ttrain-rmspe:0.081738\teval-rmspe:0.095805\n",
      "[269]\ttrain-rmse:0.075966\teval-rmse:0.09162\ttrain-rmspe:0.081612\teval-rmspe:0.095841\n",
      "[270]\ttrain-rmse:0.075844\teval-rmse:0.091587\ttrain-rmspe:0.081452\teval-rmspe:0.095809\n",
      "[271]\ttrain-rmse:0.075815\teval-rmse:0.091578\ttrain-rmspe:0.081425\teval-rmspe:0.095804\n",
      "[272]\ttrain-rmse:0.07574\teval-rmse:0.091554\ttrain-rmspe:0.081311\teval-rmspe:0.09577\n",
      "[273]\ttrain-rmse:0.075701\teval-rmse:0.091527\ttrain-rmspe:0.08127\teval-rmspe:0.095733\n",
      "[274]\ttrain-rmse:0.07561\teval-rmse:0.091522\ttrain-rmspe:0.081149\teval-rmspe:0.095733\n",
      "[275]\ttrain-rmse:0.07556\teval-rmse:0.091491\ttrain-rmspe:0.081102\teval-rmspe:0.095713\n",
      "[276]\ttrain-rmse:0.07548\teval-rmse:0.091484\ttrain-rmspe:0.080998\teval-rmspe:0.095694\n",
      "[277]\ttrain-rmse:0.075416\teval-rmse:0.091444\ttrain-rmspe:0.080932\teval-rmspe:0.095659\n",
      "[278]\ttrain-rmse:0.075332\teval-rmse:0.091407\ttrain-rmspe:0.080845\teval-rmspe:0.095618\n",
      "[279]\ttrain-rmse:0.07531\teval-rmse:0.091388\ttrain-rmspe:0.080824\teval-rmspe:0.095593\n",
      "[280]\ttrain-rmse:0.075267\teval-rmse:0.09138\ttrain-rmspe:0.08078\teval-rmspe:0.095591\n",
      "[281]\ttrain-rmse:0.075207\teval-rmse:0.091349\ttrain-rmspe:0.080721\teval-rmspe:0.095542\n",
      "[282]\ttrain-rmse:0.075095\teval-rmse:0.09127\ttrain-rmspe:0.080573\teval-rmspe:0.095459\n",
      "[283]\ttrain-rmse:0.07503\teval-rmse:0.091245\ttrain-rmspe:0.080508\teval-rmspe:0.095432\n",
      "[284]\ttrain-rmse:0.074967\teval-rmse:0.091208\ttrain-rmspe:0.080223\teval-rmspe:0.095395\n",
      "[285]\ttrain-rmse:0.074923\teval-rmse:0.091195\ttrain-rmspe:0.080179\teval-rmspe:0.095379\n",
      "[286]\ttrain-rmse:0.07487\teval-rmse:0.091171\ttrain-rmspe:0.080126\teval-rmspe:0.095359\n",
      "[287]\ttrain-rmse:0.074803\teval-rmse:0.091141\ttrain-rmspe:0.080036\teval-rmspe:0.095318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\ttrain-rmse:0.074729\teval-rmse:0.091121\ttrain-rmspe:0.079944\teval-rmspe:0.095291\n",
      "[289]\ttrain-rmse:0.07467\teval-rmse:0.091115\ttrain-rmspe:0.079873\teval-rmspe:0.095278\n",
      "[290]\ttrain-rmse:0.074626\teval-rmse:0.091135\ttrain-rmspe:0.07982\teval-rmspe:0.095293\n",
      "[291]\ttrain-rmse:0.074564\teval-rmse:0.091109\ttrain-rmspe:0.079755\teval-rmspe:0.095263\n",
      "[292]\ttrain-rmse:0.07449\teval-rmse:0.091059\ttrain-rmspe:0.07968\teval-rmspe:0.095199\n",
      "[293]\ttrain-rmse:0.074415\teval-rmse:0.091041\ttrain-rmspe:0.079558\teval-rmspe:0.095179\n",
      "[294]\ttrain-rmse:0.074333\teval-rmse:0.091043\ttrain-rmspe:0.079458\teval-rmspe:0.095185\n",
      "[295]\ttrain-rmse:0.074259\teval-rmse:0.091031\ttrain-rmspe:0.079384\teval-rmspe:0.095174\n",
      "[296]\ttrain-rmse:0.074147\teval-rmse:0.090993\ttrain-rmspe:0.079229\teval-rmspe:0.095134\n",
      "[297]\ttrain-rmse:0.074107\teval-rmse:0.090985\ttrain-rmspe:0.079183\teval-rmspe:0.095121\n",
      "[298]\ttrain-rmse:0.074024\teval-rmse:0.090959\ttrain-rmspe:0.07907\teval-rmspe:0.095094\n",
      "[299]\ttrain-rmse:0.073964\teval-rmse:0.090937\ttrain-rmspe:0.079006\teval-rmspe:0.095087\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a XGBoost model\")\n",
    "X_train, X_valid = train_test_split(train, test_size=0.012, random_state=10)\n",
    "y_train = np.log1p(X_train.Sales)\n",
    "y_valid = np.log1p(X_valid.Sales)\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \\\n",
    "  early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n",
      "RMSPE: 0.095087\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating\")\n",
    "yhat = gbm.predict(xgb.DMatrix(X_valid[features]))\n",
    "error = rmspe(X_valid.Sales.values, np.expm1(yhat))\n",
    "print('RMSPE: {:.6f}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['StateHoliday'] = test['StateHoliday'].astype(int)\n",
    "test['Assortment'] = test['Assortment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make predictions on the test set\n"
     ]
    }
   ],
   "source": [
    "print(\"Make predictions on the test set\")\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "test_probs = gbm.predict(dtest)\n",
    "# Make Submission\n",
    "result = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': np.expm1(test_probs)})\n",
    "result.to_csv(\"xgboost_10_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# XGB feature importances\n",
    "# Based on https://www.kaggle.com/mmueller/liberty-mutual-group-property-inspection-prediction/xgb-feature-importance-python/code\n",
    "\n",
    "create_feature_map(features)\n",
    "importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "featp = df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "fig_featp = featp.get_figure()\n",
    "fig_featp.savefig('feature_importance_xgb.png', bbox_inches='tight', pad_inches=1)\n",
    "\n",
    "#!/usr/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('StateHoliday', 497),\n",
       " ('Promo2', 2257),\n",
       " ('IsPromoMonth', 2610),\n",
       " ('Assortment', 3221),\n",
       " ('SchoolHoliday', 5213),\n",
       " ('StoreType', 5427),\n",
       " ('Year', 6569),\n",
       " ('Promo', 7504),\n",
       " ('Month', 15153),\n",
       " ('PromoOpen', 20662),\n",
       " ('CompetitionDistance', 22161),\n",
       " ('DayOfWeek', 23650),\n",
       " ('WeekOfYear', 23755),\n",
       " ('Store', 29970),\n",
       " ('CompetitionOpen', 30087),\n",
       " ('Day', 35520)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Idea f02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rossmann",
   "language": "python",
   "name": "rossmann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
